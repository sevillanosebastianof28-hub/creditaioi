{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Credit AI - Model Training on Google Colab\n",
    "\n",
    "This notebook trains the Credit AI machine learning models:\n",
    "- **DistilBERT Classifier**: 4-class dispute eligibility classification\n",
    "- **MiniLM Embeddings**: Semantic search and retrieval\n",
    "\n",
    "**Requirements**:\n",
    "- Google Colab account (free)\n",
    "- Runtime: GPU recommended (free tier available)\n",
    "\n",
    "**Training Time**:\n",
    "- Classifier: ~3 minutes on GPU, ~17 minutes on CPU\n",
    "- Embeddings: ~10 seconds on GPU, ~26 seconds on CPU\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Step 1: Enable GPU Runtime (Recommended)\n",
    "\n",
    "For faster training, enable GPU:\n",
    "1. Click **Runtime** â†’ **Change runtime type**\n",
    "2. Select **T4 GPU** from Hardware accelerator\n",
    "3. Click **Save**\n",
    "\n",
    "You can verify GPU availability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone"
   },
   "source": [
    "## Step 2: Clone Repository\n",
    "\n",
    "Clone the Credit AI repository from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/sevillanosebastianof28-hub/creditaioi.git\n",
    "%cd creditaioi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dependencies"
   },
   "source": [
    "## Step 3: Install Dependencies\n",
    "\n",
    "Install required Python packages for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies quietly (this may take 2-3 minutes)\n",
    "!pip install -q -r services/local-ai/requirements.txt\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "print(f\"âœ“ Transformers version: {transformers.__version__}\")\n",
    "print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_classifier"
   },
   "source": [
    "## Step 4: Train DistilBERT Classifier\n",
    "\n",
    "Train the dispute eligibility classifier:\n",
    "- **Task**: 4-class classification\n",
    "- **Classes**: eligible, conditionally_eligible, not_eligible, insufficient_information\n",
    "- **Training examples**: 1,200\n",
    "- **Expected time**: ~3 minutes on GPU, ~17 minutes on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_classifier_training"
   },
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "import os\n",
    "os.environ['CONFIG'] = 'services/local-ai/train/configs/model2_classifier.yaml'\n",
    "\n",
    "!python services/local-ai/train/train_classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify_classifier"
   },
   "source": [
    "### Verify Classifier Training\n",
    "\n",
    "Check that the classifier model was created successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_classifier"
   },
   "outputs": [],
   "source": [
    "# Check classifier model files\n",
    "!ls -lh models/finetuned/distilbert-eligibility/\n",
    "\n",
    "# Check metrics\n",
    "import json\n",
    "try:\n",
    "    with open('models/finetuned/distilbert-eligibility/test_metrics.json', 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    print(\"\\nâœ“ Classifier Training Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Could not load metrics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_embeddings"
   },
   "source": [
    "## Step 5: Train MiniLM Embeddings\n",
    "\n",
    "Train the semantic embeddings model:\n",
    "- **Task**: Semantic similarity for credit domain\n",
    "- **Training pairs**: 450\n",
    "- **Expected time**: ~10 seconds on GPU, ~26 seconds on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_embeddings_training"
   },
   "outputs": [],
   "source": [
    "# Train embeddings\n",
    "os.environ['CONFIG'] = 'services/local-ai/train/configs/model3_embeddings.yaml'\n",
    "\n",
    "!python services/local-ai/train/train_embeddings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify_embeddings"
   },
   "source": [
    "### Verify Embeddings Training\n",
    "\n",
    "Check that the embeddings model was created successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_embeddings"
   },
   "outputs": [],
   "source": [
    "# Check embeddings model files\n",
    "!ls -lh models/finetuned/minilm-embeddings/\n",
    "\n",
    "# Test embeddings model loading\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer('models/finetuned/minilm-embeddings')\n",
    "    print(\"\\nâœ“ Embeddings model loaded successfully\")\n",
    "    print(f\"  Max sequence length: {model.max_seq_length}\")\n",
    "    \n",
    "    # Test embedding generation\n",
    "    test_sentence = \"This is a test credit report dispute\"\n",
    "    embedding = model.encode(test_sentence)\n",
    "    print(f\"  Embedding dimension: {len(embedding)}\")\n",
    "    print(f\"\\nâœ“ Successfully generated test embedding\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Error loading embeddings model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate"
   },
   "source": [
    "## Step 6: Evaluate Models (Optional)\n",
    "\n",
    "Run the evaluation harness to verify model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_evaluation"
   },
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "!python scripts/evaluate_models.py\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "!cat AI_EVALUATION_REPORT.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## Step 7: Download Trained Models\n",
    "\n",
    "Package and download the trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "package_models"
   },
   "outputs": [],
   "source": [
    "# Create zip archive of trained models\n",
    "!zip -r trained_models.zip models/finetuned/\n",
    "\n",
    "# Show archive size\n",
    "!ls -lh trained_models.zip\n",
    "\n",
    "print(\"\\nâœ“ Models packaged successfully!\")\n",
    "print(\"  Archive: trained_models.zip\")\n",
    "print(\"  Contains:\")\n",
    "print(\"    - models/finetuned/distilbert-eligibility/\")\n",
    "print(\"    - models/finetuned/minilm-embeddings/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [],
   "source": [
    "# Download to your local machine\n",
    "from google.colab import files\n",
    "files.download('trained_models.zip')\n",
    "\n",
    "print(\"\\nâœ“ Download started!\")\n",
    "print(\"  Check your browser's download folder for trained_models.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "After downloading the trained models:\n",
    "\n",
    "1. **Extract the archive**:\n",
    "   ```bash\n",
    "   unzip trained_models.zip\n",
    "   ```\n",
    "\n",
    "2. **Deploy to production**:\n",
    "   - Upload to cloud storage (S3, GCS, Azure Blob)\n",
    "   - Or copy to your production server\n",
    "   - Update environment variables with model paths\n",
    "\n",
    "3. **Test the AI service**:\n",
    "   ```bash\n",
    "   cd services/local-ai\n",
    "   ENABLE_LLM=false uvicorn main:app --host 0.0.0.0 --port 8000\n",
    "   ```\n",
    "\n",
    "4. **Verify AI features**:\n",
    "   - Test classifier predictions\n",
    "   - Test embeddings generation\n",
    "   - Validate end-to-end workflow\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory (OOM) Errors\n",
    "- Enable GPU runtime if not already enabled\n",
    "- Use minimal configs: `model2_classifier_minimal.yaml`\n",
    "- Reduce batch size in config files\n",
    "\n",
    "### Import Errors\n",
    "- Restart runtime: Runtime â†’ Restart runtime\n",
    "- Re-run dependency installation cell\n",
    "\n",
    "### Training Takes Too Long\n",
    "- Verify GPU is enabled: check `torch.cuda.is_available()`\n",
    "- Expected times:\n",
    "  - Classifier: ~3 min (GPU) or ~17 min (CPU)\n",
    "  - Embeddings: ~10 sec (GPU) or ~26 sec (CPU)\n",
    "\n",
    "### Model Files Not Found\n",
    "- Check paths: models should be in `models/finetuned/*/`\n",
    "- Verify training completed without errors\n",
    "- Check disk space: Runtime â†’ Manage sessions\n",
    "\n",
    "---\n",
    "\n",
    "## Documentation\n",
    "\n",
    "For more information, see:\n",
    "- [AI_TRAINING_GUIDE.md](https://github.com/sevillanosebastianof28-hub/creditaioi/blob/main/AI_TRAINING_GUIDE.md)\n",
    "- [AI_TRAINING_STATUS.md](https://github.com/sevillanosebastianof28-hub/creditaioi/blob/main/AI_TRAINING_STATUS.md)\n",
    "- [models/README.md](https://github.com/sevillanosebastianof28-hub/creditaioi/blob/main/models/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "**Training completed successfully! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
